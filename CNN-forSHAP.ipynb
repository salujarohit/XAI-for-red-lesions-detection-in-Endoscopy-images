{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classifications of in-vivo Gastral Images - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We import a set of Python standard libraries, as well as a range of Keras features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "We need to specify a set of \"constants\" (Python does not have constants, but it really *should* be constants ;-)) that depend on the data location of the machine that runs the code.\n",
    "Note that you can get the data from https://rdm.inesctec.pt/dataset/nis-2018-003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '/home/knapics1/CNN_LIME-master/trainingMAIN/labels.txt' # Path to labels file\n",
    "data_path = '/home/knapics1/CNN_LIME-master/trainingMAIN/Set_1/A' # Path to data folder\n",
    "working_path = '/home/knapics1/CNN_LIME-master/training' # Path for (to-be-prepared) training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "First, we need to prepare our data. We split data and labels into train and validation sets (randomly assigned) and, for each set, separate *bleeding* and *non-bleeding* images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 3295; label length: 3295\n",
      "Training data length: 2993; validation data length: 302\n"
     ]
    }
   ],
   "source": [
    "training_path = f'{working_path}/training'\n",
    "validation_path = f'{working_path}/validation'\n",
    "validation_split = 0.1\n",
    "\n",
    "# read in labels\n",
    "labels_file = open(label_path, 'r')\n",
    "labels = labels_file.read().splitlines()\n",
    "\n",
    "# get data set length\n",
    "_, _, files = next(os.walk(data_path))\n",
    "data_length = len(files)\n",
    "\n",
    "print(f'Data length: {data_length}; label length: {len(labels)}')\n",
    "\n",
    "# create directory structure\n",
    "if not os.path.exists(training_path):\n",
    "    os.makedirs(training_path)\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "\n",
    "if not os.path.exists(f'{training_path}/1bleeding'):\n",
    "    os.makedirs(f'{training_path}/1bleeding')\n",
    "if not os.path.exists(f'{training_path}/0nonbleeding'):\n",
    "    os.makedirs(f'{training_path}/0nonbleeding')\n",
    "if not os.path.exists(f'{validation_path}/1bleeding'):\n",
    "    os.makedirs(f'{validation_path}/1bleeding')\n",
    "if not os.path.exists(f'{validation_path}/0nonbleeding'):\n",
    "    os.makedirs(f'{validation_path}/0nonbleeding')\n",
    "\n",
    "# copy files into directory structure\n",
    "index = 0\n",
    "\n",
    "# read in file in alphanumerical order\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "    \n",
    "for _, _, files in os.walk(data_path):\n",
    "    for file in sorted(files, key=numericalSort):\n",
    "        base_path = training_path\n",
    "        if random.uniform(0, 1) < validation_split: # assign pseudo-randomly to training or validation set\n",
    "            base_path = validation_path\n",
    "        if labels[index] == '0':\n",
    "            copyfile(os.path.join(data_path, file), f'{base_path}/0nonbleeding/{file}') \n",
    "        else:\n",
    "            copyfile(os.path.join(data_path, file), f'{base_path}/1bleeding/{file}')\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before next line copy the images you want to use to the newly generated folder training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, files1 = next(os.walk(f'{training_path}/1bleeding'))\n",
    "_, _, files2 = next(os.walk(f'{training_path}/0nonbleeding'))\n",
    "training_data_length = len(files1) + len(files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, files1 = next(os.walk(f'{validation_path}/1bleeding'))\n",
    "_, _, files2 = next(os.walk(f'{validation_path}/0nonbleeding'))\n",
    "validation_data_length = len(files1) + len(files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training data length: {training_data_length}; validation data length: {validation_data_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "training_path_non_bleeding = '/content/drive/My Drive/CNN_LIME-master/training/training/0nonbleeding'\n",
    "training_path_bleeding = '/content/drive/My Drive/CNN_LIME-master/training/training/1bleeding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data\n",
    "validation_path_non_bleeding = '/content/drive/My Drive/CNN_LIME-master/training/validation/0nonbleeding'\n",
    "validation_path_bleeding = '/content/drive/My Drive/CNN_LIME-master/training/validation/1bleeding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now, we save the model and save it to disk. For this, we use this Keras code as the blue print: https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2993 images belonging to 2 classes.\n",
      "Found 302 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "187/187 [==============================] - 76s 405ms/step - loss: 0.3041 - acc: 0.8880 - val_loss: 0.1054 - val_acc: 0.9618\n",
      "Epoch 2/50\n",
      "187/187 [==============================] - 75s 400ms/step - loss: 0.1132 - acc: 0.9666 - val_loss: 0.1341 - val_acc: 0.9479\n",
      "Epoch 3/50\n",
      "187/187 [==============================] - 75s 399ms/step - loss: 0.1177 - acc: 0.9733 - val_loss: 0.1909 - val_acc: 0.9618\n",
      "Epoch 4/50\n",
      "187/187 [==============================] - 75s 399ms/step - loss: 0.0855 - acc: 0.9789 - val_loss: 0.4424 - val_acc: 0.9444\n",
      "Epoch 5/50\n",
      "187/187 [==============================] - 76s 405ms/step - loss: 0.0859 - acc: 0.9806 - val_loss: 0.2141 - val_acc: 0.9688\n",
      "Epoch 6/50\n",
      "187/187 [==============================] - 74s 395ms/step - loss: 0.1180 - acc: 0.9750 - val_loss: 0.1045 - val_acc: 0.9688\n",
      "Epoch 7/50\n",
      "187/187 [==============================] - 74s 395ms/step - loss: 0.0855 - acc: 0.9843 - val_loss: 0.1477 - val_acc: 0.9722\n",
      "Epoch 8/50\n",
      "187/187 [==============================] - 73s 393ms/step - loss: 0.1359 - acc: 0.9779 - val_loss: 0.0976 - val_acc: 0.9688\n",
      "Epoch 9/50\n",
      "187/187 [==============================] - 73s 393ms/step - loss: 0.0651 - acc: 0.9860 - val_loss: 0.3597 - val_acc: 0.9653\n",
      "Epoch 10/50\n",
      "187/187 [==============================] - 74s 394ms/step - loss: 0.0863 - acc: 0.9816 - val_loss: 0.1109 - val_acc: 0.9722\n",
      "Epoch 11/50\n",
      "187/187 [==============================] - 74s 394ms/step - loss: 0.0887 - acc: 0.9816 - val_loss: 0.1230 - val_acc: 0.9618\n",
      "Epoch 12/50\n",
      "187/187 [==============================] - 73s 392ms/step - loss: 0.0684 - acc: 0.9833 - val_loss: 0.0830 - val_acc: 0.9826\n",
      "Epoch 13/50\n",
      "187/187 [==============================] - 74s 394ms/step - loss: 0.0879 - acc: 0.9853 - val_loss: 1.0440 - val_acc: 0.9236\n",
      "Epoch 14/50\n",
      "187/187 [==============================] - 74s 396ms/step - loss: 0.1055 - acc: 0.9843 - val_loss: 0.3167 - val_acc: 0.9618\n",
      "Epoch 15/50\n",
      "187/187 [==============================] - 1914s 10s/step - loss: 0.0941 - acc: 0.9863 - val_loss: 0.3056 - val_acc: 0.9688\n",
      "Epoch 16/50\n",
      "187/187 [==============================] - 2072s 11s/step - loss: 0.1543 - acc: 0.9840 - val_loss: 0.4592 - val_acc: 0.9583\n",
      "Epoch 17/50\n",
      "187/187 [==============================] - 75s 401ms/step - loss: 0.0910 - acc: 0.9890 - val_loss: 0.2389 - val_acc: 0.9722\n",
      "Epoch 18/50\n",
      "187/187 [==============================] - 76s 407ms/step - loss: 0.0949 - acc: 0.9870 - val_loss: 0.2223 - val_acc: 0.9757\n",
      "Epoch 19/50\n",
      "187/187 [==============================] - 75s 402ms/step - loss: 0.1271 - acc: 0.9853 - val_loss: 0.2168 - val_acc: 0.9792\n",
      "Epoch 20/50\n",
      "187/187 [==============================] - 75s 403ms/step - loss: 0.1116 - acc: 0.9880 - val_loss: 0.2278 - val_acc: 0.9688\n",
      "Epoch 21/50\n",
      "187/187 [==============================] - 75s 400ms/step - loss: 0.0715 - acc: 0.9873 - val_loss: 0.4401 - val_acc: 0.9653\n",
      "Epoch 22/50\n",
      "187/187 [==============================] - 75s 400ms/step - loss: 0.1403 - acc: 0.9833 - val_loss: 0.4178 - val_acc: 0.9722\n",
      "Epoch 23/50\n",
      "187/187 [==============================] - 75s 400ms/step - loss: 0.1067 - acc: 0.9860 - val_loss: 0.5203 - val_acc: 0.9583\n",
      "Epoch 24/50\n",
      "187/187 [==============================] - 76s 407ms/step - loss: 0.0850 - acc: 0.9873 - val_loss: 0.2865 - val_acc: 0.9757\n",
      "Epoch 25/50\n",
      "187/187 [==============================] - 4758s 25s/step - loss: 0.1921 - acc: 0.9810 - val_loss: 0.3913 - val_acc: 0.9653\n",
      "Epoch 26/50\n",
      "187/187 [==============================] - 5462s 29s/step - loss: 0.0796 - acc: 0.9906 - val_loss: 0.3040 - val_acc: 0.9757\n",
      "Epoch 27/50\n",
      "187/187 [==============================] - 83s 441ms/step - loss: 0.0692 - acc: 0.9913 - val_loss: 0.3830 - val_acc: 0.9722\n",
      "Epoch 28/50\n",
      "187/187 [==============================] - 76s 405ms/step - loss: 0.0728 - acc: 0.9903 - val_loss: 0.2344 - val_acc: 0.9757\n",
      "Epoch 29/50\n",
      "187/187 [==============================] - 74s 393ms/step - loss: 0.1329 - acc: 0.9880 - val_loss: 0.2769 - val_acc: 0.9653\n",
      "Epoch 30/50\n",
      "187/187 [==============================] - 74s 395ms/step - loss: 0.0822 - acc: 0.9903 - val_loss: 0.3195 - val_acc: 0.9792\n",
      "Epoch 31/50\n",
      "187/187 [==============================] - 74s 395ms/step - loss: 0.1255 - acc: 0.9886 - val_loss: 0.0775 - val_acc: 0.9931\n",
      "Epoch 32/50\n",
      "187/187 [==============================] - 74s 398ms/step - loss: 0.1056 - acc: 0.9910 - val_loss: 0.4309 - val_acc: 0.9688\n",
      "Epoch 33/50\n",
      "187/187 [==============================] - 75s 401ms/step - loss: 0.1010 - acc: 0.9900 - val_loss: 0.4085 - val_acc: 0.9722\n",
      "Epoch 34/50\n",
      "187/187 [==============================] - 2277s 12s/step - loss: 0.0829 - acc: 0.9910 - val_loss: 0.1195 - val_acc: 0.9896\n",
      "Epoch 35/50\n",
      "187/187 [==============================] - 7961s 43s/step - loss: 0.0652 - acc: 0.9947 - val_loss: 0.3719 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "187/187 [==============================] - 80s 430ms/step - loss: 0.1175 - acc: 0.9883 - val_loss: 0.2974 - val_acc: 0.9792\n",
      "Epoch 37/50\n",
      "187/187 [==============================] - 76s 407ms/step - loss: 0.1095 - acc: 0.9893 - val_loss: 0.1775 - val_acc: 0.9826\n",
      "Epoch 38/50\n",
      "187/187 [==============================] - 75s 402ms/step - loss: 0.1103 - acc: 0.9890 - val_loss: 0.3355 - val_acc: 0.9722\n",
      "Epoch 39/50\n",
      "187/187 [==============================] - 77s 412ms/step - loss: 0.0719 - acc: 0.9923 - val_loss: 0.3497 - val_acc: 0.9757\n",
      "Epoch 40/50\n",
      "187/187 [==============================] - 77s 410ms/step - loss: 0.1157 - acc: 0.9900 - val_loss: 0.1900 - val_acc: 0.9826\n",
      "Epoch 41/50\n",
      "187/187 [==============================] - 76s 405ms/step - loss: 0.1051 - acc: 0.9896 - val_loss: 0.2662 - val_acc: 0.9826\n",
      "Epoch 42/50\n",
      "187/187 [==============================] - 76s 404ms/step - loss: 0.0716 - acc: 0.9920 - val_loss: 1.1541 - val_acc: 0.9028\n",
      "Epoch 43/50\n",
      "187/187 [==============================] - 80s 428ms/step - loss: 0.1032 - acc: 0.9903 - val_loss: 0.3363 - val_acc: 0.9722\n",
      "Epoch 44/50\n",
      "187/187 [==============================] - 2785s 15s/step - loss: 0.1092 - acc: 0.9900 - val_loss: 0.1445 - val_acc: 0.9826\n",
      "Epoch 45/50\n",
      "187/187 [==============================] - 79s 424ms/step - loss: 0.1294 - acc: 0.9876 - val_loss: 0.2848 - val_acc: 0.9792\n",
      "Epoch 46/50\n",
      "187/187 [==============================] - 75s 401ms/step - loss: 0.1288 - acc: 0.9880 - val_loss: 0.1125 - val_acc: 0.9931\n",
      "Epoch 47/50\n",
      "187/187 [==============================] - 75s 399ms/step - loss: 0.0966 - acc: 0.9903 - val_loss: 0.2795 - val_acc: 0.9826\n",
      "Epoch 48/50\n",
      "187/187 [==============================] - 75s 401ms/step - loss: 0.1121 - acc: 0.9896 - val_loss: 0.1921 - val_acc: 0.9861\n",
      "Epoch 49/50\n",
      "187/187 [==============================] - 75s 402ms/step - loss: 0.0833 - acc: 0.9930 - val_loss: 0.4220 - val_acc: 0.9722\n",
      "Epoch 50/50\n",
      "187/187 [==============================] - 75s 399ms/step - loss: 0.1377 - acc: 0.9890 - val_loss: 0.2587 - val_acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "nb_train_samples = training_data_length\n",
    "nb_validation_samples = validation_data_length\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3/anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
